{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e10ed22-ca75-4fe5-b468-62b0ca8bee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e84692097e243e8ad7deb344d275301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/2043 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a8a7f7a1a04ccb9bb2b744b387a990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/2043 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c80a82c1ad5475dadb672fde334218b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/2043 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cc247ae8ac4eb3b129dfff0735682e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/2043 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdf627312284b1fba8f05922cf13e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/2043 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6be23655a374ca1875e992e47ce1cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/2043 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c136fafb3745f68e1fd8fb7ac06cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/2042 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval dataset length: 2860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.874704550543627, 'recall': 0.9079803719008265, 'f1': 0.891031895885342}\n",
      "v2\n",
      "{'precision': 0.7489993084225748, 'recall': 0.9230371900826446, 'f1': 0.8269606765621204}\n",
      "Eval dataset length: 2860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8690023630946265, 'recall': 0.8992132681267276, 'f1': 0.8838497309159308}\n",
      "v2\n",
      "{'precision': 0.740963725426728, 'recall': 0.9126355517754625, 'f1': 0.8178884058834038}\n",
      "Eval dataset length: 2860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8675240046404857, 'recall': 0.9099523612261806, 'f1': 0.888231800548416}\n",
      "v2\n",
      "{'precision': 0.7441647024467575, 'recall': 0.9236743993371996, 'f1': 0.8242592271703344}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import datetime\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, AutoConfig, DataCollatorWithPadding\n",
    "from transformers.trainer_utils import set_seed\n",
    "from transformers.integrations import WandbCallback\n",
    "from scipy.special import expit\n",
    "\n",
    "from data import NERDataModule\n",
    "from config import get_configs\n",
    "from model import get_pretrained\n",
    "from utils import (\n",
    "    kaggle_metrics,\n",
    "    kaggle_metrics2,\n",
    "    DataCollatorWithMasking,\n",
    "    set_wandb_env_vars,\n",
    "    reinit_model_weights,\n",
    ")\n",
    "from callbacks import NewWandbCB, SaveCallback, MaskingProbCallback, BasicSWACallback\n",
    "from sift import SiftTrainer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    config_file = \"j-dv3l-repl-2-pp-cv.yml\"\n",
    "    output = config_file.split(\".\")[0]\n",
    "    cfg, args = get_configs(config_file)\n",
    "    set_seed(args[\"seed\"])\n",
    "    \n",
    "    cfg[\"model_name_or_path\"] = cfg[\"model_name_or_path\"].format(fold=0)\n",
    "\n",
    "    datamodule = NERDataModule(cfg)\n",
    "    datamodule.prepare_datasets()\n",
    "\n",
    "    for fold in range(3):\n",
    "\n",
    "        cfg, args = get_configs(config_file)\n",
    "        cfg[\"fold\"] = fold\n",
    "        cfg[\"model_name_or_path\"] = cfg[\"model_name_or_path\"].format(fold=fold)\n",
    "        args[\"output_dir\"] = f\"{output}-f{fold}\"\n",
    "\n",
    "        args = TrainingArguments(**args)\n",
    "\n",
    "        eval_dataset = datamodule.get_eval_dataset(fold=fold)\n",
    "        \n",
    "        print(f\"Eval dataset length: {len(eval_dataset)}\")\n",
    "        compute_metrics = partial(kaggle_metrics, dataset=eval_dataset)\n",
    "\n",
    "        model_config = AutoConfig.from_pretrained(cfg[\"model_name_or_path\"], use_auth_token=os.environ.get(\"HUGGINGFACE_HUB_TOKEN\", True))\n",
    "\n",
    "        model = get_pretrained(model_config, cfg[\"model_name_or_path\"]+\"/pytorch_model.bin\")\n",
    "\n",
    "        data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=datamodule.tokenizer,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "        )\n",
    "\n",
    "        Trainer = SiftTrainer if cfg.get(\"use_sift\") else Trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            tokenizer=datamodule.tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        trainer.remove_callback(WandbCallback)\n",
    "\n",
    "        preds = trainer.predict(eval_dataset.remove_columns([x for x in eval_dataset.column_names if x not in {\"input_ids\", \"attention_mask\", \"token_type_ids\"}]))\n",
    "        \n",
    "        print(kaggle_metrics(preds, eval_dataset))\n",
    "        print(\"v2\")\n",
    "        print(kaggle_metrics2(preds, eval_dataset))\n",
    "        \n",
    "\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a89cc-d2b6-4ace-8aec-c3b66a0c04cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
